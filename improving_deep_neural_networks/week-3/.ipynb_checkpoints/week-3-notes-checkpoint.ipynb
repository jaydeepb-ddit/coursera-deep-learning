{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Notes\n",
    "\n",
    "## Tuning Process\n",
    "\n",
    "Hyperparameters are parts of the neural network learning architecture that are treated as fixed. They are not learned from the data directly - because they would lower the training error but not aid generalization. Additionally, usually there is no clean way to learn them from data even if we wanted - because of the computational load.\n",
    "\n",
    "Instead we rely on another split of the data and use a pseudo empirical Bayes procedure to find the best hyperparameters. This is a great discussion from [stackoverflow](https://stats.stackexchange.com/questions/365762/why-dont-we-just-learn-the-hyper-parameters).\n",
    "\n",
    "```\n",
    "A hyperparameter typically corresponds to a setting of the learning algorithm, rather than one of its parameters. In the context of deep learning, for example, this is exemplified by the difference between something like the number of neurons in a particular layer (a hyperparameter) and the weight of a particular edge (a regular, learnable parameter).\n",
    "\n",
    "Why is there a difference in the first place? The typical case for making a parameter a hyperparameter is that it is just not appropriate to learn that parameter from the training set. For example, since it's always easier to lower the training error by adding more neurons, making the number of neurons in a layer a regular parameter would always encourage very large networks, which is something we know for a fact is not always desirable (because of overfitting).\n",
    "\n",
    "To your question, it's not that we don't learn the hyper-parameters at all. Setting aside the computational challenges for a minute, it's very much possible to learn good values for the hyperparameters, and there are even cases where this is imperative for good performance; all the discussion in the first paragraph suggests is that by definition, you can't use the same data for this task.\n",
    "\n",
    "Using another split of the data (thus creating three disjoint parts: the training set, the validation set, and the test set, what you could do in theory is the following nested-optimization procedure: in the outer-loop, you try to find the values for the hyperparameters that minimize the validation loss; and in the inner-loop, you try to find the values for the regular parameters that minimize the training loss.\n",
    "\n",
    "This is possible in theory, but very expensive computationally: every step of the outer loop requires solving (till completion, or somewhere close to that) the inner-loop, which is typically computationally-heavy. What further complicates things is that the outer-problem is not easy: for one, the search space is very big.\n",
    "\n",
    "There are many approaches to overcome this by simplifying the setup above (grid search, random search or model-based hyper-parameter optimization), but explaining these is well beyond the scope of your question. As the article you've referenced also demonstrates, the fact that this is a costly procedure often means that researchers simply skip it altogether, or try very few setting manually, eventually settling on the best one (again, according to the validation set). To your original question though, I argue that - while very simplistic and contrived - this is still a form of \"learning\".\n",
    "\n",
    "```\n",
    "\n",
    "### Examples of Hyperparameters\n",
    "\n",
    "THere are many kinds of hyperparameters that one might want to tune. A good strategy (found empirically) is to tune in the following sequence:\n",
    "\n",
    "1. learning rate $alpha$\n",
    "\n",
    "1. number of hidden units, minibatch size, $\\beta$ of Adam algorithm\n",
    "\n",
    "1. number of layers, learing rate decay\n",
    "\n",
    "1. Almost never done in practice, but is possible to tune $\\beta_1, \\beta_2, \\epsilon$. Defaults (0.9, 0.999, $10^{-8}$) are usually good enough.\n",
    "\n",
    "\n",
    "### Hyperparameter Search Strategy\n",
    "\n",
    "There are some strategies that can be tried:\n",
    "\n",
    "\n",
    "1. grid search - usually discouraged as computationally expensive.\n",
    "\n",
    "1. random search - known to produce good results, but can be wasteful. Can also use coarse to fine search scheme where after some time, finding a promising neighborhood with good possibilities, we focus our search around that area - this is similar to the next section.\n",
    "\n",
    "1. Bayesian hyperparameter optimization - balancing exploitation vs exploration.\n",
    "\n",
    "There has been some innovation in this space, notes can be found [here](https://www.automl.org/wp-content/uploads/2018/09/chapter1-hpo.pdf)\n",
    "\n",
    "## Using An Appropriate Scale\n",
    "\n",
    "If we have a range for a parameter - which in itself is a task, then often using an appropriate scale that reflects the relative change can be a better sampling space. One good choice can be to sample from the log space. \n",
    "\n",
    "This could be for quantities such as:\n",
    "\n",
    "- $\\alpha$ sampled on log space\n",
    "- $\\beta$ sampled from $log(1-\\beta)$\n",
    "\n",
    "\n",
    "## HyperParameter Tuning In Practice\n",
    "\n",
    "\n",
    "\n",
    "## Normalizing Activations In A Network\n",
    "\n",
    "## Fitting Batch Norm Into Networks\n",
    "\n",
    "## Why Does Batch Norm Work?\n",
    "\n",
    "## Batch Norm At Test Time\n",
    "\n",
    "## SoftMax Regression\n",
    "\n",
    "## Training SoftMax Regression\n",
    "\n",
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
