{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week2 Notes\n",
    "\n",
    "It's possible to cast a logistic regression as a simple neural network.  This is what we do here, along with introducting the backward pass and forward pass as part of the computation graph. Finally, we introduce a vectorized implementation and demonstrate its improved efficiency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression as a Neural Network\n",
    "Casting logistic regression as a neural network.\n",
    "\n",
    "### Binary Classification\n",
    "\n",
    "The problem of Binary classification, is one of finding a mapping from a feature vector $\\mathbf{x}$ to a target $y$ - y must be 1 or 0 - from examples in a historical dataset.\n",
    "\n",
    "The 'hello world' problem in machine learning (at least for computer vision) is one of learning a mapping of an image ($x$) as either having a cat in the image ($y=1$) or not $y=0$.\n",
    "\n",
    "An image is an array of numbers (from 0 to 255) made up of 3 channels (one for each of Red, Green and Blue) across the height and width of the image. Each number is the intensity of the pixel in each color channel at a given location in the image. We can think of this as a 3 dimensional array, $A$. The way to get a feature vector $x$ from $A$ is to unroll, unravel, or reshape $A$ into a vector. \n",
    "\n",
    "For an image that is $64$x$64$ pixels, there are $64$x$64$x$3$$ =1228$ numbers that make up the feature vector. The length of the feature vector is referenced as $n = n_{X}$.\n",
    "\n",
    "Let's say we have $m = m_{train}$ examples of images with cats and without cats in them. Then we can define the data as a feature matrix $X$, target vector $Y$ as below:\n",
    "\n",
    "$$\n",
    "X = \\left [ x^{(1)}, \\ldots,  x^{(m)} \\right ]\n",
    "$$\n",
    "$$\n",
    "Y = \\left [ y^{(1)}, \\ldots,  y^{(m)} \\right ]\n",
    "$$\n",
    "\n",
    "In this setting `X` is a matrix with `X.shape = (m, n)`, and `Y` is a row vector with `Y.shape = (1, m)`. This mean that the individual $x^{(i)}$ are column vectors.\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "In the logistic regression model, we specify that a linear combination of the features, $x$, as inputs to a non-linear function, in this case the sigmoid function. It produces an estimate of the chance that $y$ is 1, $P(y=1|x) = \\hat{y}$, as opposed to explicitly trying to model the target as as function of $x$.\n",
    "\n",
    "If we tried to model the target, we can't get a smooth function that maps to 1 or 0 only. By using the sigmoid we ensure that the probability of $y$ being 1 is explicitly modelled, and bounded between 0 and 1. The sigmoid function is:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\left( 1 + e^{-z} \\right)^{-1}\n",
    "$$\n",
    "\n",
    "\n",
    "We will see later, that for hidden layers it might make sense to allow the non-linear function, also called the activation function, to be a hyperparameter.\n",
    "\n",
    "If the linear combination is a large number, then $P(y=1|x)$ gets very close to 1. Using a certain framework (Maximum A Prior or MAP) we can predict that in such cases y will be 1.\n",
    "\n",
    "If the linear combination is a large negative number, then  $P(y=1|x)$ gets very close to 0. Using the MAP framework we can predict that in such cases y will be 1.\n",
    " \n",
    "If the linear combination is close to 0, then $P(y=1|x)$ is close to 0.5. Under MAP we can make a prediction either side of 0.5 (> 0.5 to 1, <0.5 to 0), but we can't be very sure about which it is.\n",
    "\n",
    "#### with explicit bias `b`\n",
    "\n",
    "Using parameters $\\mathbf{w} = [w_1, \\ldots, w_n]$ (a column vector) and b, a scalar bias parameter. We model $\\hat{y}$ as $\\hat{y} = \\sigma(w^{T}x + b)$.\n",
    "\n",
    "#### with implicit bias $\\theta_0$\n",
    "\n",
    "If we extend x by adding $x_0=1$, set an example feature as $x = (x_0, \\ldots, x_n)$ and define $(w, b) = \\mathbf{\\theta}$ - still a column vector, with $\\theta_0 = b$ then it we can write this model as:\n",
    "\n",
    "$\\hat{y} = \\sigma(\\mathbf{\\theta}^{T}x)$\n",
    "\n",
    "This formulation is not preferred because by having the bias term explicitly available, some of the future arithmetic becomes easier to understand.\n",
    "\n",
    "### Logistic Regression Cost Function\n",
    "\n",
    "It is desirable that as we learn the parameters of the logistic regression that for each of the examples in our dataset, we try for each example $i$, to make $\\hat{y^{(i)}}$ as close to $y^{(i)}$ as possible. We can measure the loss, or distance, of each estimate $\\hat{y^{(i)}}$ from the ideal target $y^{(i)}$ using a function $L$. Some candidate $L$ functions are:\n",
    "\n",
    "1. $L(y, \\hat{y}) = |y - \\hat{y}|$\n",
    "\n",
    "1. $L(y, \\hat{y}) = \\frac{1}{2}(y - \\hat{y})^2$\n",
    "\n",
    "1. $L(y, \\hat{y}) = - \\left [ y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y}) \\right ]$\n",
    "\n",
    "Of these, the third loss function has many desirable properties such as: \n",
    "\n",
    "* differentiable, smooth and convex with unique optima (can be confirmed by taking second derivative wrt parameters)\n",
    "* a natural mapping to the negative log-likelihood (discussed later)\n",
    "\n",
    "The first is the most compelling, later we will explain second part - the negative log-likelihood. So we can change the parameters $w$ and $b$ until we reach a low loss.\n",
    "\n",
    "Since we want to reduce the loss for all the dataset, then we can use the individual losses to define an averaged loss function over all examples. This is called the cost function J of the dataset. That is:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}, b) = \\frac{1}{m}\\sum_{i=1}^{m} L(y^{(i)}, \\hat{y^{(i)}})\n",
    "=  \\frac{-1}{m}\\sum_{i=1}^{m}  \\left [ y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y}) \\right ]\n",
    "$$\n",
    "\n",
    "Because of our choice of loss function (convex and smooth), we can guarantee that J has a single global optima. \n",
    "\n",
    "By iterating using a Taylor series approximation (known as gradient descent) we converge to the optimal parameters that minimize the cost function. \n",
    "\n",
    "These parameters define a classification rule, or classifier to model the binary data.\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "#### Deriving The Algorithm\n",
    "\n",
    "##### Derivation from Taylor's Therorem\n",
    "\n",
    "By Taylor's theorem we note that for a well behaved smooth multivariate function F:\n",
    "\n",
    "$$\n",
    "F(\\mathbf{x} + \\mathbf{h}) \\approx  F(\\mathbf{x}) + \\mathbf{h} \\cdot \\nabla F(\\mathbf{x}) + \\mathbf{h} \\cdot \\nabla^2 F(\\mathbf{x}) \\cdot \\mathbf{h}^T\n",
    "$$\n",
    "\n",
    "We can rewrite this with the substitution, $\\mathbf{x}_t = \\mathbf{x} + \\mathbf{h}$ and \n",
    "$\\mathbf{x}_{t-1} = \\mathbf{x}$:\n",
    "\n",
    "$$\n",
    "F(\\mathbf{x}_t) \\approx  F(\\mathbf{x}_{t-1}) + (\\mathbf{x}_{t} -\\mathbf{x}_{t-1}) \\cdot \\nabla F(\\mathbf{x}_{t-1}) + (\\mathbf{x}_{t} -\\mathbf{x}_{t-1}) \\cdot \\nabla^2 F(\\mathbf{x}_{t-1}) \\cdot (\\mathbf{x}_{t} -\\mathbf{x}_{t-1})^T\n",
    "$$\n",
    "\n",
    "\n",
    "Near an optima, $\\mathbf{x}_{opt}$, $\\nabla F(\\mathbf{x}_{opt}) = \\mathbf{0}$. So if we say that $\\mathbf{x}_{t}$ is close to the optima:\n",
    "\n",
    "$$\n",
    "F(\\mathbf{x}_t) \\approx  F(\\mathbf{x}_{t-1}) +  (\\mathbf{x}_{t} -\\mathbf{x}_{t-1}) \\cdot \\nabla^2 F(\\mathbf{x}_{t-1}) \\cdot (\\mathbf{x}_{t} -\\mathbf{x}_{t-1})^T\n",
    "$$\n",
    "\n",
    "\n",
    "Rearranging, and noting that $-(\\mathbf{x}_{t} -\\mathbf{x}_{t-1})^{-1}(F(\\mathbf{x}_t) -  F(\\mathbf{x}_{t-1})) \\approx  - \\nabla F(\\mathbf{x}_{t-1})$, we have:\n",
    "\n",
    "$$\n",
    " - \\nabla F(\\mathbf{x}_{t-1}) \\approx \\nabla^2 F(\\mathbf{x}_{t-1}) \\cdot (\\mathbf{x}_{t} -\\mathbf{x}_{t-1})^T\n",
    "$$\n",
    "\n",
    "And taking another approximation to the inverse hessian, by a constant (can check dimensions on array multiplications to see that this works):\n",
    "\n",
    "$$\n",
    "- \\alpha  \\nabla F(\\mathbf{x}_{t-1}) \\approx\\ (\\mathbf{x}_{t} -\\mathbf{x}_{t-1})\n",
    "$$\n",
    "\n",
    "Then rearrraning, we have the famous gradient descent algorithm:\n",
    "\n",
    "From a nearby good starting point $x_{0}$ , and small enough $\\alpha$, if we repeat this iteration enough times:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t}  \\approx  \\mathbf{x}_{t-1}  - \\alpha \\nabla F(\\mathbf{x}_{t-1})\n",
    "$$\n",
    "\n",
    "Then for some R, All $T > R$ will have $x_{T}$ being arbitrarily close to $x_{opt}$.\n",
    "\n",
    "##### Derivation From Gradient Defintion\n",
    "\n",
    "The definition of the gradient at a point is the instantaneous slope at that point. This gradient is the fastest direction on the surface where the function is increasing.\n",
    "\n",
    "So if we want to decrease the function, the best direction is the opposite of the gradient by some small enough amount ($\\alpha$) where the gradient approximation is close to the function.  The tension is setting $\\alpha$ small enough to be valid but large enough to make progress.\n",
    "\n",
    "For the 1 dimensional case: If the gradient is positive, then the function is increasing, and we should go in the opposite direction (and increase our point) to reduce the function. If the gradient is negative then we should go in the opposite direction to follow it to a lower value (and reduce our point).\n",
    "\n",
    "Using this logic, is how we get:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t}  \\approx  \\mathbf{x}_{t-1}  - \\alpha \\nabla F(\\mathbf{x}_{t-1})\n",
    "$$\n",
    "\n",
    "#### Cost Function\n",
    "\n",
    "With our logistic function, $J$ is a convex surface over the parameter space. Because of this convexity, we can initialize our parameters anywhere in the space, conventionally the zero vector is chosen for w and 0 for b.\n",
    "\n",
    "Now we do our iterative process \n",
    "\n",
    "\n",
    "### Derivatives\n",
    "\n",
    "Here Professor Ng provides an understanding of the gradient as a rate of change, using simple analytic examples with numbers. Essentially the point being driven home is:\n",
    "\n",
    "$$\n",
    "F(a + h) - F(a) \\approx h \\frac{\\partial F}{\\partial x} |_{@x=a}\n",
    "$$\n",
    "\n",
    "### More Derivatives Examples\n",
    "More of the same, some more complex examples with non-constant gradients.\n",
    "\n",
    "\n",
    "### Computation Graph\n",
    "\n",
    "Here Professor Ng shows the composite expressions defining an expression can be used to evaluate a function. The major reason this is useful is for caching results,  the forward and the backward propogation of the neural network algorithm. Not that:\n",
    "\n",
    "- Forward propogation: Substituting intermediate quantities to calculate cost function. \n",
    "- Backward propogation: Substituting chain rule (intermediate derivatives) to calculate derivatives of cost function with respect to parameters.\n",
    "\n",
    "### Derivatives with a Computation Graph\n",
    "\n",
    "A detailed example of derivatives using the chain rule, numerical examples on a simple compound function. The substitutions can be viewed on the computation graph - a directed acyclic graph.\n",
    "\n",
    "In code, we note the convention that for a function that is principal and being optimized, say $J$. we denote its derivative wrt some variable $a$ $\\frac{\\delta J}{da}$ as `da`. This avoids repeatedly referencing the function to be optimized in lengthy token names such as `dJ_over_da`.\n",
    "\n",
    "\n",
    "### Logistic Regression Gradient Descent\n",
    "\n",
    "Here we calculate the intermediate derivative quantities needed to complete the chain rule. That is derivatives of the composition functions, to get the chain-ruled derivative of the loss function with respect to the parameters $\\mathbf{w}$ and b.\n",
    "\n",
    "Firstly note that the loss function can be expressed as a composite of:\n",
    "\n",
    "- $z(w,b;t) = w^Tt +b$\n",
    "\n",
    "- $\\sigma(t) = g(t)= (1 + e^{-t})^{-1}$\n",
    "\n",
    "- $a(t) = \\hat{y}^{(t)} = g(t) = \\sigma(t)$\n",
    "\n",
    "- $e(t, r) = t\\log(r)$\n",
    "\n",
    "- $L(t, r) = -e(t, r) - e(1-t, 1-r)$\n",
    "\n",
    "In fact we can see that $L$ is:\n",
    "\n",
    "$$L(y,\\hat{y}) = - \\left[ e(y, \\sigma(z(w,b;x)) + e(1-y, 1 - \\sigma(z(w,b;x)) \\right ]$$\n",
    "\n",
    "The derivatives of these functions are:\n",
    "\n",
    "$ \\frac{\\partial}{\\partial w} z(w,b;t) = t $\n",
    "\n",
    "$ \\frac{\\partial}{\\partial b} z(w,b;t) = \\mathbf{1} $\n",
    "\n",
    "$ \\frac{\\partial}{\\partial t} \\sigma(t) = \\sigma(t)(1 - \\sigma(t)) $\n",
    "\n",
    "$ \\frac{\\partial}{\\partial t} \\hat{y}^{(t)} = \\hat{y}^{(t)}(1 - \\hat{y}^{(t)}) $\n",
    "\n",
    "$ \\frac{\\partial}{\\partial r} e(t, r) = \\frac{t}{r}$\n",
    "\n",
    "$ \\frac{\\partial}{\\partial r} e(1 - t, 1 - r) = -\\frac{1-t}{1-r}$\n",
    "\n",
    "$ \\frac{\\partial}{\\partial r} L(t, r) = - \\left( \\frac{t}{r} + -\\frac{1-t}{1-r} \\right ) = \\frac{r-t}{r(1-r)}\n",
    "$\n",
    "\n",
    "#### Derivative Of The Loss Function\n",
    "\n",
    "Now to compute the derivative of the loss function wrt to $w$ and $b$, for an example which has feature $\\mathbf{x}$ and target $y$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w} L(y,\\hat{y}) = \\frac{\\partial L}{\\partial r} \\cdot \\frac{\\partial y}{\\partial \\sigma} \\cdot \\frac{\\partial \\sigma}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w} = (\\hat{y} - y) \\mathbf{x} = (a - y) \\mathbf{x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b} L(y,\\hat{y}) = \\frac{\\partial L}{\\partial r} \\cdot \\frac{\\partial y}{\\partial \\sigma} \\cdot \\frac{\\partial \\sigma}{\\partial z} \\cdot \\frac{\\partial z}{\\partial b} = (\\hat{y} -y) = (a-y)\n",
    "$$\n",
    "\n",
    "### Gradient Descent on `m` Examples\n",
    "\n",
    "Now all that remains is to combine the results from above for the cost function, which is just an average of the individual losses across the dataset. Since that's just a linear combination of the individual losses, the derivative of the cost function function will be a linear combination of the derivatives of the individual losses. \n",
    "\n",
    "#### Derivative of Cost Function\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w} J(w, b; X, Y)  = \\frac{1}{m} \\sum_i (a^{(i)} -y^{(i)}) \\mathbf{x}^{(i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b} J(w, b; X, Y)  = \\frac{1}{m} \\sum_i (a^{(i)} -y^{(i)})\n",
    "$$\n",
    "\n",
    "#### Gradient Descent on Cost Function\n",
    "\n",
    "We are given starting point, $(\\mathbf{w}_0,b_0)$ usually chosen as the zero vector and zero for logistic regression, and  some sequence $\\alpha_{k}$ (maybe constant), convergence criteria $\\epsilon$ and some max number of iterations. \n",
    "\n",
    "Run the follow iteration until convergence or the maximum number of iterations allowed:\n",
    "\n",
    "$ \\mathbf{w}_{k} = \\mathbf{w}_{k-1} - \\alpha_{k} \\frac{1}{m} \\sum_i (a^{(i)} - y^{(i)})\\mathbf{x}^{(i)} $\n",
    "\n",
    "$ b_{k} = b_{k-1} - \\alpha_{k} \\frac{1}{m} \\sum_i (a^{(i)} -y^{(i)}) $\n",
    "\n",
    "Remember that for all $i$,  $a^{(i)}$ depend on $w_{k-1}$ and $b_{k-1}$ as well as $i$.\n",
    "\n",
    "We'll now implement this as `python` unvectorized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def z(w, b, x):\n",
    "    res = b\n",
    "    for i in range(len(w)):\n",
    "        res +=w[i]*x[i]\n",
    "    return res\n",
    "\n",
    "def sigma(z):\n",
    "    return (1 + math.exp(-z))**(-1)\n",
    "\n",
    "def a(w, b, x):\n",
    "    return sigma(z(w,b,x))\n",
    "\n",
    "def gradient_of_cost_fn(X, Y, w, b):\n",
    "    n = len(X)\n",
    "    m = len(X[0])\n",
    "    for j in range(m):\n",
    "        z = z(w, b, X[:][j])\n",
    "        a = sigma(z)\n",
    "        dz = a - Y[j]\n",
    "        for i in range(n):\n",
    "            dw[j] += dz * X[i][j]\n",
    "        db += dz\n",
    "    return (dw, db)\n",
    "\n",
    "def unvectorized_gradient_descent(X, Y, gradient_fn, w0 = None, b0 = None, \n",
    "                                  alpha = 0.001, epsilon = 1e-6, max_iter= 1000):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    m = len(X[0])\n",
    "    if w0 is None:\n",
    "        w0 = [0 for i in range(n)]\n",
    "    if b0 is None:\n",
    "        b0 = 0\n",
    "    w_old = w0\n",
    "    b_old = b0\n",
    "    iter_count = 1\n",
    "    while True:\n",
    "        dw, db = gradient_of_cost_fn(X, Y, w_old, b_old)\n",
    "        w_new -= alpha * dw\n",
    "        b_new -= alpha * db \n",
    "        if iter_count > max_iter or (abs(w_new - w_old) < epsilon and abs(b_new - b_old) < epsilon):\n",
    "            break\n",
    "        iter_count += 1\n",
    "        w_old, b_old = w_new, b_new\n",
    "    return (w_new, b_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation should work, however it will be super slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy and Vectorization\n",
    "Python is great easy to learn language. However, because of this easy of use, many data structures such as tuples and lists involve linked lists and type checking. For millions of numbers, as occur in machine learning, this can be a heavy bottleneck.\n",
    "\n",
    "`numpy` is a python module which defines its own array-like data structure, which is highly optimized by setting a single type (avoids type checking overhead) and storing data in contingous blocks of memory.\n",
    "\n",
    "### Vectorization\n",
    "\n",
    "We'll do a comparison of vectorized vs unvectorized code - both with numpy arrays. The main difference illustrated here is that vectorization involves significant speed up because loops is pushed down into the numpy inteface and done using single instruction multiple data (SIMD) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random((int(1e6), 1))\n",
    "z = np.random.random((int(1e6), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvectorized result: [249561.16873465]\n",
      "Time taken for unvectorized calculation 225.06029605865479 ms\n"
     ]
    }
   ],
   "source": [
    "# unvectorized dot product\n",
    "tic = time.time()\n",
    "res = 0\n",
    "for i in range(w.shape[0]):\n",
    "    res += w[i] * z[i]\n",
    "toc = time.time()\n",
    "print(f'Unvectorized result: {res}')\n",
    "print(f'Time taken for unvectorized calculation {str(100 * (toc - tic))} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized result: [[249561.16873466]]\n",
      "Time taken for vectorized calculation 1.2671947479248047 ms\n"
     ]
    }
   ],
   "source": [
    "# vectorized dot product\n",
    "# unvectorized dot product\n",
    "tic = time.time()\n",
    "res = np.dot(w.T, z)\n",
    "toc = time.time()\n",
    "print(f'Vectorized result: {res}')\n",
    "print(f'Time taken for vectorized calculation {str(100 * (toc - tic))} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 2000 times faster to use vectorized result. That's the difference of 1 second or 33 minutes for a calculation to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Vectorization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 373.86600971221924 ms\n"
     ]
    }
   ],
   "source": [
    "# unvectorized: matrix-vector matrix product\n",
    "n, m = int(1e3), int(1e3)\n",
    "A = np.random.random((n, m))\n",
    "x = np.random.random((m, 1))\n",
    "tic = time.time()\n",
    "res = np.zeros((m, 1))\n",
    "for i in range(A.shape[0]):\n",
    "    for j in range(A.shape[1]):\n",
    "        res[i] += A[i,j] * x[j]\n",
    "toc = time.time()\n",
    "#print(f'unvectorized result: {res}')\n",
    "print(f'Time taken for unvectorized calculation {str(100 * (toc - tic))} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 0.07259845733642578 ms\n"
     ]
    }
   ],
   "source": [
    "# vectorized: matrix-vector matrix product\n",
    "tic = time.time()\n",
    "res = np.dot(A, x)\n",
    "toc = time.time()\n",
    "#print(f'unvectorized result: {res}')\n",
    "print(f'Time taken for unvectorized calculation {str(100 * (toc - tic))} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher order function to time vectorized and unvectorized calculations\n",
    "def timing_vectorization(fn, x = None):\n",
    "    if x is None: \n",
    "        x = np.random.random((int(1e6),1))\n",
    "    tic = time.time()\n",
    "    res = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        res +=  eval(f'np.{fn}(x[i])')\n",
    "    toc = time.time()\n",
    "    #print(f'Unvectorized result: {res}')\n",
    "    unvectored_diff = 100 * (toc - tic)\n",
    "    print(f'Time taken for unvectorized calculation {str(unvectored_diff)} ms')\n",
    "    tic = time.time()\n",
    "    res = eval(f'np.{fn}(x)')\n",
    "    toc = time.time()\n",
    "    vectored_diff = 100* (toc - tic)\n",
    "    print(f'Time taken for unvectorized calculation {str(vectored_diff)} ms')\n",
    "    print(f'Ratio of vectored to unvectored calculation time: {str(round(unvectored_diff/vectored_diff, 5))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 1.5041112899780273 ms\n",
      "Time taken for unvectorized calculation 0.0072956085205078125 ms\n",
      "Ratio of vectored to unvectored calculation time: 206.16667\n"
     ]
    }
   ],
   "source": [
    "# exp\n",
    "timing_vectorization('exp', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 1.5859127044677734 ms\n",
      "Time taken for unvectorized calculation 0.0036954879760742188 ms\n",
      "Ratio of vectored to unvectored calculation time: 429.14839\n"
     ]
    }
   ],
   "source": [
    "# log\n",
    "timing_vectorization('log', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 1.8209218978881836 ms\n",
      "Time taken for unvectorized calculation 0.006318092346191406 ms\n",
      "Ratio of vectored to unvectored calculation time: 288.20755\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "timing_vectorization('max', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 1.8707990646362305 ms\n",
      "Time taken for unvectorized calculation 0.0054836273193359375 ms\n",
      "Ratio of vectored to unvectored calculation time: 341.16087\n"
     ]
    }
   ],
   "source": [
    "# min\n",
    "timing_vectorization('min', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 1.4233112335205078 ms\n",
      "Time taken for unvectorized calculation 0.0041961669921875 ms\n",
      "Ratio of vectored to unvectored calculation time: 339.19318\n"
     ]
    }
   ],
   "source": [
    "# abs\n",
    "timing_vectorization('abs', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 1.5565156936645508 ms\n",
      "Time taken for unvectorized calculation 0.0030040740966796875 ms\n",
      "Ratio of vectored to unvectored calculation time: 518.13492\n"
     ]
    }
   ],
   "source": [
    "# reciprocal\n",
    "timing_vectorization('reciprocal', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for unvectorized calculation 1.5377998352050781 ms\n",
      "Time taken for unvectorized calculation 0.0032901763916015625 ms\n",
      "Ratio of vectored to unvectored calculation time: 467.3913\n"
     ]
    }
   ],
   "source": [
    "# square\n",
    "timing_vectorization('square', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Logistic Regression\n",
    "\n",
    "Let's work through the calculations earlier for backward and forward propogation to get a faster optimization algorithm. As before, we have feature matrix $X$ and target vector $Y$. \n",
    "\n",
    "#### Forward Propogation\n",
    "\n",
    "$$ \\hat{Y} = A =  \\sigma(wX + b \\mathbf{1}^T) $$\n",
    "\n",
    "#### Backward Propogation\n",
    "\n",
    "$ dZ = A - Y $ is an intermediate quantity calculated from above. `dZ.shape = (m, 1)`. This helps to calculates the gradient with respect to the parameters.\n",
    "\n",
    "$d\\mathbf{w} = \\frac{X(dZ)^T}{m}$ the vector of weights (`dW.shape = (n,1)`)\n",
    "\n",
    "$db = \\frac{\\mathbf{1}(dZ)^T}{m} = \\frac{ \\sum_i (dZ)_i}{m}$, the scalar bias\n",
    "\n",
    "\n",
    "These can then be used in the gradient descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in Numpy\n",
    "\n",
    "In numpy, broadcasting expands vectors/matrices so that binary calculations can be confirmed. There are three rules to this.\n",
    "\n",
    ">\n",
    "> * Rule 1: If the two arrays differ in their number of dimensions, the shape of the one with >fewer dimensions is padded with ones on its leading (left) side.\n",
    ">\n",
    "> * Rule 2: If the shape of the two arrays does not match in any dimension, the array with >shape equal to 1 in that dimension is stretched to match the other shape.\n",
    ">\n",
    "> * Rule 3: If in any dimension the sizes disagree and neither is equal to 1, an error is raised.\n",
    " >\n",
    " from https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape  # column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broadcasing the constant into a column vector and then addition applied\n",
    "(x + 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Numpy Vectors\n",
    "\n",
    "One needs to take care with vectors that are 1d. A vector x is 1d if: `x.shape = (1,)`. Such vectors are neither row vectors (`row_vector.shape = (n,1)`) or column vectors (`column_vector.shape = (1,m)`) and exhibit counter-intuitive behaviour. For example, applying a transpose doesn't change the shape of a 1d vector. \n",
    "\n",
    "Care should be taken to avoid such vectors as much as possible. One way is to provide `keepdims=True` argument to operations that would otherwise collapse dimensions into a 1d vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Logistic Regression Cost Function\n",
    "\n",
    "The logistic regression cost function, $J$, is the negative log-likelihood (nll) of assuming that the data are bernoulli observations of a varying probability which changes with each example. A sigmoid transform of a linear combination of the features estimates the probability of each example being $1$ or $0$. \n",
    "\n",
    "This is a discriminative model, making no assumptions about the distribution of the features.\n",
    "\n",
    "Formally:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(y | x) = p^y (1-p)^{(1-y)}$\n",
    "\n",
    "where p is estimated by $\\hat{y}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
