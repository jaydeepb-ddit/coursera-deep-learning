{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Many applications in computer vision are now solved by deep learning. There are two benefits from studying these problems and solutions:\n",
    "\n",
    "* There is still scope for creating products and applications using deep learning inspired computer vision techniques.\n",
    "\n",
    "*  The computer vision community has been very inventive in solving problems using deep learning. Their approaches can provide insight when working on other problems such as speech or text.\n",
    "\n",
    "Computer vision is concerned mostly with inputs that are image or video data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of CV Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Classification\n",
    "\n",
    "Classifying an object as one of several classes (one of which may be the background or unassigned class). The simplest case is a binary classifier - the canonical teaching example being a cat classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Detection\n",
    "\n",
    "object detection is the compound task of finding an object (bounding box or scene pixel segmentation) and then classifying it from an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Style Transfer\n",
    "\n",
    "Neural style transfer is taking two images - from one of them the neural style is extracted, the other is then redone using the neural style to create a new image; a combination of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face Recognition\n",
    "The face recognition task is to locate a face in an image and then check if it matches one of the faces in a register or else return an unmatched classification if it is not matched. The particular desired properties of such a classifier are specific to the details of the application. For example face recognition to access a bank account needs a very high precision, but low recall is acceptable - because giving the wrong person access is not permitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Large Inputs: Deep Learning on High Resolution Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Scaling Problem with Large Inputs\n",
    "\n",
    "When the inputs run into the millions, then training a fully connected neural network becomes very difficult, because the number of training parameters can run into the billions of hundreds of billions. Even with current compute, it will just take too long and too much compute to train a FCNN.\n",
    "\n",
    "Image data at high resolution will easily have millions of pixels of input - hence a different approach is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Convolution Operation Mitigates Scaling on Large Inputs\n",
    "\n",
    "The convolution operator applies a filter to regions of an image. For each region it computes pairwise multiplications and then sums over various regions of an image. The output of the filter is a multidimensional array storing the mul-sums of each.\n",
    "\n",
    "The convolution operation effectively shares parameters (the filter weights) locally across inputs, thus needing fewer parameters and less compute to be learned.\n",
    "\n",
    "Using the convolution operator it becomes possible to learn levels of features, be robust to rotations and still lead to good outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of An Image\n",
    "\n",
    "Finding interesting features of an image involves find areas where there is the greatest change in an image. One way to do this is it find the derivative of an image.\n",
    "\n",
    "Since an image is a discretized representation, the smallest change is 1 unit. Looking at forward, backward and central derivatives these are just different representations of the approximate derivative:\n",
    "\n",
    "* Forward: `f(x+1) - f(x)`\n",
    "\n",
    "* Central: `f(x+1) -f(x-1)`\n",
    "\n",
    "* Backward: `f(x) -f(x-1)`\n",
    "\n",
    "To get a good estimate of the derivative of a pixel we average around it. Usually given that a pixel will have 8 direct neighbors, using the 8 local pixels is common. It total 9 pixels will be used to compute the \n",
    "\n",
    "It can be shown that these and other derivatives are just masks applied to an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the layers of a CNN are colloquially referred to as convolutions, this is only by convention.\n",
    "\n",
    "Mathematically, the operation is technically a sliding dot product or cross-correlation of an image against a filter. This can be expressed using the numpy einsum function, based on einstein notation.\n",
    "\n",
    "The filter aka a kernel in the literature, is an array of equal or smaller size that is positioned (or overlayed) over various sub regions of an image. \n",
    "\n",
    "For each sub region (like a subsample), a single number is returned - the sum of the hadamard product matrix of the filter over the region. This output is stored in the output matrix - whose size will be determined by the size of the image and the size of the kernel - sequentially. The output size is actually `(n - f + 1) x (n - f + 1)`, where `n` is the size of the image and `f` is the size of the filter.\n",
    "\n",
    "This convolution is technically a cross correlation of the filter and the image.\n",
    "\n",
    "`sliding_dot_product(image_subsample, filter)` is the calculation that finds the .\n",
    "\n",
    "A convolutional neural network consists of an input and an output layer, as well as multiple hidden layers. The hidden layers of a CNN typically consist of a series of convolutional layers that convolve with a multiplication or other dot product. \n",
    "\n",
    "The activation function is commonly a RELU layer, and is subsequently followed by additional convolutions such as pooling layers, fully connected layers and normalization layers, referred to as hidden layers because their inputs and outputs are masked by the activation function and final convolution. The final convolution, in turn, often involves backpropagation in order to more accurately weight the end product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection Examples\n",
    "\n",
    "### Vertical Edge Detection\n",
    "\n",
    "Different filters detect different aspects of an image. We'll show a hard-coded filter (a 3x3 vertical edge filter) being applied to an image here. \n",
    "\n",
    "First a simple example of the mechanics involved in calculating a sliding dot product. This is for a filter_arr that fits exactly into the image_arr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_dot_product(image_arr, filter_arr):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vertical Edge Filter\n",
    "\n",
    "Here is a vertical edge filter. This filter is looking for an edge by differentiating the image with respect to the 8 local pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, -1],\n",
       "       [ 1,  0, -1],\n",
       "       [ 1,  0, -1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v_edge_filter = np.array([1,0,-1,1,0,-1,1,0,-1]).reshape((3,3))\n",
    "v_edge_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel is a simple array, which is calculating the central derivative and averaging it along the x-axis, hence we look rapid changes along the vertical axis, which demonstrate a vertical edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Image With No Vertical Edges\n",
    "\n",
    "We're going to apply a filter.\n",
    "\n",
    "#### Example 2: Image With Clear Vertical Edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Edge Detection\n",
    "\n",
    "### Vertical Filters\n",
    "\n",
    "### Horizontal Filters\n",
    "\n",
    "### General Edge Filters\n",
    "\n",
    "#### Sobel Filter\n",
    "\n",
    "#### Scharr Filter\n",
    "\n",
    "### Learning Filters\n",
    "\n",
    "\n",
    "## Padding\n",
    "\n",
    "## Strided Convolutions\n",
    "\n",
    "## Convolutions Over Volumes\n",
    "\n",
    "## One Layer Of A Convolutional Network\n",
    "\n",
    "## Simple Convolutional Network Example\n",
    "\n",
    "## Pooling Layers\n",
    "\n",
    "## CNN Example\n",
    "\n",
    "## Why Convolutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
