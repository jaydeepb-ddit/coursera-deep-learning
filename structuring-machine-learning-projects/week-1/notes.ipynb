{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Model Performance\n",
    "\n",
    "Why is having a disciplined machine learning strategy important? Suppose we train a computer algorithm for a machine learning task. Its performance is not acceptable - we need to improve. There are many changes we can try making to the system, including:\n",
    "\n",
    "* Collect more data\n",
    "\n",
    "* Collect more diverse training data (balance)\n",
    "\n",
    "* Change convergence criteria \n",
    "    - train for more iterations (if using iterative approach)\n",
    "    - train until change is within epsilon\n",
    " \n",
    "* Try different initial parameters\n",
    "\n",
    "* Try different algorithms\n",
    "\n",
    "* Try bigger network (more parameters/complexity)\n",
    "\n",
    "* Try smaller network (more parameters/complexity)\n",
    "\n",
    "* Try dropout\n",
    "\n",
    "* Add regularization\n",
    "\n",
    "* Change Network Architecture\n",
    "    - number of activation units in different layers\n",
    "    - number of hidden layers\n",
    "    - different activation function\n",
    "\n",
    "* Data Augmentation\n",
    "    - artificial data\n",
    "    - similar data\n",
    "    \n",
    "* Bootstrapping\n",
    "\n",
    "* Bagging\n",
    " \n",
    "* Boosting \n",
    " \n",
    "* Early Stopping\n",
    "\n",
    "Changing these controls essentially produces a new classifier each time. We are then trying to select the best classifier by altering the settings for how it is trained on which kind of data.\n",
    "\n",
    "Almost all of these are good ideas - having different effects depending on the reason underlying unacceptable performance. However, without a strategy we could go in circles trying one thing and then another - possibly wasting time and resources and not getting optimal results. \n",
    "\n",
    "A principled way of diagnosing problems and applying remedies leads to better performance which can be reasoned about much sooner.\n",
    "\n",
    "The difference might be seen as akin to a well trained doctor having good diagnostic tools vs someone with a lot of experience seeing various kinds of illnesses but not having a logical and sound framework to improve with.\n",
    "\n",
    "An important part of applying the right changes is doing them with a sense of fairness - that is that if we change one aspect of the algorithm or data then it should have just one measurable effect on the performance - ideally something that we can reason about.\n",
    "\n",
    "## Orthogonalization\n",
    "\n",
    "In many problems it is convenient to find a set of aspects or system of controls that lets us change one and not change the other controls, only the quantity (for example performance metric) that we are interested in. \n",
    "\n",
    "![](orthogonal_vectors.png)\n",
    "\n",
    "One example is a co-ordinate system. If we have a set of orthogonal basis vectors then changing the size of one them does not change the others - the basis vectors are perpendicular to each other. If we worked in a non-orthogonal set of basis vectors then change the size of one vector impacts the co-ordinates of the others as well as changing distance.\n",
    "\n",
    "![](non_orthogonal_vectors.png)\n",
    "\n",
    "Another is the controls of a vehicle. Speed and direction are in separate controls (steering wheel and pedals). Changing the speed, influences the distance traveled, but it does not change the direction. Direction also influences the distance, but doesn't affect speed. It is conceivable to create controls that change both direction and speed at the same time, making it much harder to understand and achieve the desired action.\n",
    "\n",
    "![car navigation example](steering_wheel_accelerator_brake.jpg)\n",
    "\n",
    "Another example is an old CRT TV. These televisions had controls or knobs that change height, width, vertical center and horizontal center. There are 4 controls so that each one impacts just one axis. These were carefully set. If instead we had controls that moved both the horizontal and vertical center in one knob - it would be a lot more work.\n",
    "\n",
    "![Old TV](crt_controls.jpg)\n",
    "\n",
    "Similarly, with respect to machine learning performance, we want to have controls that influence performance but not the other controls that we may want to change. Some controls such as \"early stopping\" are not orthogonal to the others and so we don't consider them. We also suggest that one control at a time is changed to see its effect on performance.\n",
    "\n",
    "We will spend the rest of the course understanding how we can identify the reasons for the poor performance and what changes can be expected from change certain controls.\n",
    "\n",
    "## Single Number Evaluation Metric\n",
    "\n",
    "In some cases it might be natural that our performance measure is a vector of numbers. In that case we need to choose one or create one from the vector. It becomes difficult if not impossible to order between a collection of vectors if some go up and others down as we change a control.\n",
    "\n",
    "If we need to optimize a vector of metrics the best suggestion is to compromise and approximate this with a function that takes the vector of metrics as input and outputs a scalar. It can become too difficult to select which control setting to choose otherwise.\n",
    "\n",
    "![single number metric](single_metric_f1.png)\n",
    "\n",
    "One example is wanting a binary classifier to have high precision and high recall. For this, the recommended strategy is to combine recall and precision into their harmonic sum - which is also called the micro-f1 score. Then this f1 score should be improved by changing the controls.\n",
    "\n",
    "For the example above we can order by the f1 score and choose the logistic classifier as the best of them. \n",
    "\n",
    "If we just tried comparing precision and recall, we could only discount the SVM and decision tree as it has strictly worse recall and precision compared to the logistic classifer and random forest respectively. However the other classifiers are dominant in one or other of recall and precision so we don't have a preference relation over them. \n",
    "\n",
    "By having a single metric over a vector we effectively create a utility function that values the different vectors by utility.\n",
    "\n",
    "## Satisficing And Optimizing Metrics\n",
    "\n",
    "Sometimes we might not have a good utility function over the metrics we monitor for the problem in mind.\n",
    "\n",
    "### One Optimizing Metric And Many Satisficing Metrics\n",
    "\n",
    "If we have $N$ metrics on a classifier family and no natural utility function over them, we might still have conditions on the metric vector, to help us choose between them.\n",
    "\n",
    "Often we can set one metric as that to be optimized and the others as having some constraint to be satisfied. A good solution is then to put constraints to be satisfied on $N-1$ metrics and retain one to be optimized.\n",
    "\n",
    "By doing this, we can focus on a single number metric, while still chasing desirable features.\n",
    "\n",
    "### Example: Accuracy and Runtime\n",
    "\n",
    "### Example: Wake Word\n",
    "\n",
    "## Train/Dev/Test Distributions\n",
    "\n",
    "## Proportions Of Train/Dev/Test Sets\n",
    "\n",
    "## When To Change Dev/Test Sets\n",
    "\n",
    "## Why Human Level Performance\n",
    "\n",
    "## Avoidable Bias\n",
    "\n",
    "## Understanding Human Level Performance\n",
    "\n",
    "## Surpassing Human Level Performance\n",
    "\n",
    "## Improving Model Performance\n",
    "\n",
    "## Carrying Out Error Analysis\n",
    "\n",
    "## Cleaning Up Incorrectly Labeled Data\n",
    "\n",
    "## Build First System Quickly - Then Iterate\n",
    "\n",
    "## Training And Testing On Different Distributions\n",
    "\n",
    "## Bias And Variance With Mismatched Data\n",
    "\n",
    "## Addressing Data Mismatch\n",
    "\n",
    "## Transfer Learning\n",
    "\n",
    "## Multitask Learning\n",
    "\n",
    "## What is End-To-End Deep Learning\n",
    "\n",
    "## Whether To Use End-To-End Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
